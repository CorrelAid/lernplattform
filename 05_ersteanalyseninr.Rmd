## Daten verstehen in R

Nina: wir könnten den Code natürlich auch komplett verstecken und ihnen nur die Ergebnisse zeigen (Fokus: Interpretation). Dann sollte sich die Übung konsequenterweise auch um Interpretation drehen.

![*Video: Erste Datenanalysen in R (30min)*](https://youtu.be/58i2_o-zDug)
*Empfehlung: Schaut Euch das Video in zwei Teilen an. Bis 18:42 geht es um Visualisierung, danach um statistische Kennzahlen.*

<!-- Nina: Sollen wir hier die programmatischen Sachen rausnehmen und eher theoretische Ausführungen ergänzen? -->
### Kernaussagen
#### Grundlagen der Datenanalyse
- Konzeptionell sollten wir uns von **Fragen zur Exploration, möglichen Plausibilitätschecks und Fallentscheidungen** leiten lassen, die während der Analyse beantwortet werden
- Bei einer Datenanalyse nutzen wir zunächst niedrigschwellige **tabellarische Formate** wie `summary()` und `str()`, um uns einen Überblick über die Daten zu verschaffen
- Danach helfen uns **einfache Datenvisualisierungen**, die Ausprägungen von Variablen zu untersuchen (und Extremwerte zu identifizieren)
- Um weitere Operationen durchführen zu können, berechnen wir im Anschluss **statistische Kennzahlen**, Lage- und Verteilungsparameter, die für uns spannende Informationen enthalten und die Grundlage für weitere Analysen bilden

#### Visuelle Exploration
- **`ggplot2`** ist ein Paket für vielseitige **Graphiken** in R
- Die wichtigsten Schichten (Bestandteile) eines ggplots sind: 
    1. `data` - der **Datensatz**
    2. `aes()` - die **"ästhetischen Attribute"** wie die x- oder y-Achse und Darstellungsoptionen
    3. `geom_*()` - die **geometrische Form**, mit welcher die Werte dargestellt werden, z.B. geom_point() für Punktediagramme oder geom_bar() für Bardiagramme
- Einzelne Bestandteile werden mit einem **"+" verknüpft** 

Im Kapitel "Datenvisualisierung" lernt Ihr, wie ihr diese Graphen in R erstellen könnt. In diesem Kapitel geht es, um die Interpretation. 

#### Statistische Kennzahlen
- Mittels statistischer Kennzahlen lassen sich **Datensätze zusammenfassen** und Fragen an den Datensatz zu beantworten
- Besonders oft werden folgende Funktionen genutzt: 
    - `min()`: **minimale Ausprägung** einer Variablen
    - `max()`: **maximalen Ausprägung** einer Variablen
    - `median()`: **Median**, der "wahre" Mittelpunkt (50% der Ausprägungen sind kleiner oder größer)
    - `mean()`: arithmetische Mittel, Durchschnitt oder schlicht **Mittelwert**
    - `var()`: **Varianz**, die Streuung um den Mittelwert
    - `sd()`: **Standardabweichung**, ein standardisiertes Maß für die Streuung um den Mittelwert (auch: mittlere Abweichung), es ist die Wurzel aus der Varianz.
    - `n()`: **Anzahl** bzw. absolute Häufigkeiten der Ausprägungen
    - `sum()`: **Summe** numerischer Variablen.
- Darüber hinaus möchten wir schon folgende **`tidyverse`** Operationen hervorheben:
    - `dplyr::summarize()` - **Zusammenfassung von Werten** zur Vereinfachung des Informationsgehalts
    - `dplyr::group_by()` - **Gruppierung von Zielen** (Beobachtungen) nach Kriterien
- Diese sind eine Art **Power-Duo**. Denn mit `dplyr::group_by()` & `dplyr::summarize()` können statistische Kennzahlen **pro Variablenkategorie** (z.B. Land) ausgegeben werden.
- Verknüpft werden Operationen von *`dplyr`* mit dem **Pipe-Operator "%>%"** (zu dt. Rohrbetreiber), der eine ähnliche Funktion wie das "+" in `ggplot2` erfüllt.

Im Kapitel "Datenbereinigung" lernt Ihr diese Funktionen des tidyverse in R noch ausführlicher kennen. 

Für diese Lektion benötigt Ihr also zwei Packages: `dplyr`und `ggplot2` (beide Teil des `tidyverse`)
```{r pakete_ersteanalysen, exercise = TRUE}
# install.packages("dplyr")
# install.packages("ggplot2")
library(dplyr)
library(ggplot2)
```

### Quiz
```{r quiz_ersteanalyseninr}
quiz(caption = NULL,
  question("Welche Aussagen sind wahr?",
    answer("Es ist ausreichend statistische Kennzahlen zu berechnen, um Aussagen über die Bedeutung erhobener Daten zu treffen."),
    answer("Es ist ausreichend Visualisierungen zu erstellen, um Aussagen über die Bedeutung erhobener Daten zu treffen."),
    answer("Kontext ist bei rigoroser Datenanalyse nicht so wichtig."),
    answer("Die Berechnung statistischer Kennzahlen, die Visualisierung und die Kontextualisierung sind eine wichtige Grundlage (!) für die Interpretation von Daten und komplexere Analysen.", correct = TRUE),
    correct = "Richtig!",
    incorrect = "Leider falsch. Die Berechnung statistischer Kennzahlen, die Visualisierung und die Kontextualisierung sind eine wichtige Grundlage (!) für die Interpretation von Daten und komplexere Analysen.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen"
  ),
  question("Was sind alles Lagemaße einer Verteilung?",
    answer("25%-Quantil - 25% der Werte ver Verteilung sind kleiner, der Rest ist größer. ", correct = TRUE),
    answer("Median - die wahre Mitte der Ausprägungen", correct = TRUE),
    answer("Mittelwert - der Durchschnitt", correct = TRUE),
    answer("Maximum - der höchste Wert"),
    answer("Minimum - der niedrigste Wert"),
    correct = "Richtig!",
    incorrect = "Leider falsch: Mit Maximum und Minimum berechnen wir lediglich die Spannbreite, die selbst ein Streuungsparameter ist.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen"
  ),
  question("Der Mittelwert ist robust gegen Ausreißer.",
    answer("Wahr"),
    answer("Unwahr", correct = TRUE),
    correct = "Richtig!",
    incorrect = "Leider falsch: Der Mittelwert kann durch Ausreißer stark verzerrt werden. Robuster ist der Median.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen"
  ),
  question("Der Mittelwert der Zufallsvariable betrögt 5, die Spannbreite 10 und die Standardabweichung 2. Um wie viel weichen Beobachtungen im Mittel von dem Wert 5 ab?",
    answer("2", correct = TRUE),
    answer("5"),
    answer("10"),
    correct = "Richtig!",
    incorrect = "Leider falsch: Die Standardabweichung sagt aus, um wie viel im Mittel eine Beobachtung von dem Mittelwert abweicht (hier 2).",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen"
  ),
  question("Mit dem Package ggplot2 können...",
    answer("Daten visualisiert werden.", correct = TRUE),
    answer("Statistische Kennzahlen und Übersichtstabellen berechnet werden."),
    answer("Daten importiert werden."),
    answer("Daten bereinigt werden."),
    correct = "Richtig! Die Datenbereinigung und die Berechnung von statistischen Kennzahlen und Übersichtstabellen erfolgen mit dplyr. Für den Import gibt es ganz viele Möglichkeiten, aber dazu in späteren Kapiteln mehr...",
    incorrect = "Leider falsch: Visualierungen erstellen wir u.a. mit ggplot2. Die Datenbereinigung und die Berechnung von statistischen Kennzahlen und Übersichtstabellen erfolgen mit dplyr. Für den Import gibt es ganz viele Möglichkeiten, aber dazu in späteren Kapiteln mehr...",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen"
  )
)
```


### Interaktive Übung

#### Fragen
Am Anfang jeder Datenanalyse steht etwas, dass zunächst gar nichts mit Daten zu tun haben muss: Fragen. Da Daten letztlich Informationen formalisieren, nutzen wir die Ergebnisse einer Datenanalyse in der Regel für den **Erkenntnisgewinn**. Möchten wir Daten erheben oder liegen uns diese bereits vor vor, hilft es, sich auf bestimmte Fragestellungen zu fokussieren, die sich aus strategischen Überlegungen ergeben.

Der [Datensatz](https://github.com/rfordatascience/tidytuesday/tree/master/data/2021/2021-01-26){target="_blank"} von **"Break Free From Plastic"** stammt aus den Jahren 2019 und 2020. Da es in dieser Einheit darum geht, in den **Analyse-Spirit** zu kommen und R als Analysetool kennenzulernen, haben wir den Datensatz "Break Free from Plastic" bereits **bereinigt** und in **zwei Datensätze** aufgeteilt: der Community Datensatz (als `community` hinterlegt) enthält alle Variablen, welche für Fragestellungen rundum die Community-Perspektive nützlich sind und der Audit Datensatz (als `audit` hinterlegt), umfasst jene Variablen, die für Fragen zur Audit-Perspektive nützlich sind. Da 2020 auch für die Initiative ein besonderes Jahr war, konzentrieren wir uns auf 2019.

Versetzen wir uns die Rolle der Organisator:innen. Sie fragen sich bestimmt, wie erfolgreich ihre Aktivitäten im Jahre 2019 waren:

  1. Wie viel Plastik wurde insgesamt gesammelt? <br>
  2. Wie viel Plastik wurde durchschnittlich je Kontinent gesammelt? <br>
  3. Welche Faktoren beeinflussen möglicherweise diese Unterschiede? <br>


#### Datenstruktur
Um diese Fragen zu beantworten, schauen wir nun auf die Informationen, die uns vorliegen: Wir analysieren die dazu vorliegenden Daten und interpretieren die Ergebnisse.

Mit der Funktion **`dplyr::glimpse()`** erhaltet Ihr einen Überblick über die Struktur des Datensatzes (Anzahl der Beobachtungen, Anzahl der Variablen, Name und Datentyp der Variablen). Der `community` Datensatz enthält geographische und zeitliche Variablen sowie Daten zur gesammelten Plastikmenge, Veranstaltungen und Freiwilligen. Eine Zeile (auch: Beobachtung) entspricht einem Land.
```{r exercise_community, exercise = TRUE}
# Überblick über die Community verschaffen
dplyr::glimpse(community)
```

```{r quiz_kurzstatistik}
quiz(caption = NULL,
  question(
    "Wie viele Variablen hat der `community`-Datensatz?",
    answer("Das kann man anhand des Outputs nicht sagen."),
    answer("51"),
    answer("5", correct = TRUE),
    answer("7"),
    correct = "Richtig!",
    incorrect = "Leider falsch: 5 Variablen sind enthalten.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen",
    random_answer_order = TRUE
  ),
  
  question(
    "Welche Variablen gibt die Anzahl an gesammelten Plastikstücken an?",
    answer("Das kann man anhand des Outputs nicht sagen."),
    answer("n_volunteers"),
    answer("n_pieces", correct = TRUE),
    answer("n_events"),
    correct = "Richtig!",
    incorrect = "Leider falsch: n_pieces gibt die Anzahl an Plastikstücken, die in einem Land gesammelt wurden an.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen",
    random_answer_order = TRUE
    )
  )
```

Wir sehen, dass die Variablen, die Spalten in unserem Datensatz, unterschiedliche Formate haben. `continent` und `country` haben die Class "character", weil sie aus Text/ Buchstaben bestehen. Statistisch gesehen sind sie **nominal skalierte** Variablen, da sie Kategorien sind, ohne Ranking und ohne numerischen Wert. Alle anderen Variablen `n_...` sind **metrisch skalierte** Variablen. Wir können sie der Größe nach sortieren und mit ihnen ganz natürlich rechnen. Zwar nicht in unserem Datensatz aber zur Vollständigkeit: es gibt auch noch **ordinal skalierte** Variablen, z.B. Schulnoten, diese haben eine Rangreihenfolge, die Abstände zwischen den Rängen können wir aber nicht sinnvoll interpretieren. Es ist wichtig sich dieser Skalenniveaus bewusst zu sein, um die richtigen statistischen Kennzahlen für eine Variable zu finden. 


#### Erster Überblick
Nun kennen wir den Grundaufbau des Datensatzes schon und möchten die Variablen, die für unsere Fragestellungen interessant sind besser verstehen. Dazu geben wir uns mit `summary()`` **erste (statistische) Eigenschaften** der Variablen aus.

```{r summary_community}
# Zusammenfassung anzeigen lassen
summary(community)
```

```{r quiz_plausibilisierung}
quiz(
  caption = NULL,
  
  question(
    "Was ist der niedrigste Wert, den die Variable n_pieces annimmt?",
    answer("Das kann man anhand des Outputs nicht sagen."),
    answer("68.5"),
    answer("1.0", correct = TRUE),
    answer("120646.0"),
    correct = "Richtig!",
    incorrect = "Leider falsch: 1 Plastikstück ist der niedrigste Wert.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen",
    random_answer_order = TRUE
  ),
  
  question(
    "Die Spannweite gibt die Differenz zwischen dem größten und dem kleinsten Wert einer Variable an. Wie plausibel findet ihr die Spannweite der Variable n_pieces?",
    answer("Das kann man anhand des Outputs nicht sagen."),
    answer("Viel zu groß."),
    answer("Plausibel", correct = TRUE),
    answer("Viel zu klein"),
    correct = "Richtig! Wir sehen keine negativen Werte und auch die Größenordnung erscheint nicht unplausibel.",
    incorrect = "Leider falsch: Die Spannweite erscheint plausibel: wir sehen keine negativen Werte und auch die Größenordnung ist vorstellbar ",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen",
    random_answer_order = TRUE
  )

  )

```


#### Datenvisualisierung
Ebenso zur Datenexploration gehört die Visualisierung der Rohdaten. Dafür erstellen wir ein Punktediagramm (*engl. Scatterplot*), genauer: Einen Beeswarmplot (*dt. Bienenschwarmdiagramm*). Diese Visualisierung stellt sowohl die Verteilung als auch die Häufigkeit von Beobachtungen über die Verteilung dar. Nehmt Euch einen Moment und beschreibt die Graphik in Euren Worten. Wo würdet Ihr den Mittelwert verorten? Markiert ihn gedanklich auf der Visualisierung. <br>
*Anmerkung: In der Lektion Datenvisualisierung erstellen wir diese Graphik dann gemeinsam. Heute geht es zunächst um die Interpretation.*

```{r geom_point_n_pieces_bericht, exercise = TRUE}
# Erstellung eines Boxplots mit Punktewolke zur Anzahl gesammelter Plastikstücke pro Kontinent
ggplot(data = community, aes(x = continent, y = n_pieces, fill = continent)) + # Initialisierung des ggplots mit Variablen
  ggbeeswarm::geom_beeswarm(size = 3, alpha = 0.5, color = "darkgrey") + # Hinzufügen der Datenpunkte (Scatterplot) inkl. Stylingoptionen zur Punktegröße, Transparenz und Farbe zur Verdeutlichung der Anzahl
  labs(
    title = "Auch die Anzahl gesammelter Plastikstücke von 'Break Free From Plastic' ..." ,
    subtitle = "... unterscheidet sich nach Kontinent.",
    y = "Anzahl gefundener Plastikstücke",
    x = "Kontinent",
    caption = glue::glue("n = {nrow(community)} \nDatenquelle: TidyTuesday und BFFP")) + # Festlegung der Achsenbezeichungen, Überschriften und Titel
  theme_minimal() + # Festlegung des Layout-Designs  
  theme(legend.position="none") + # Ausblenden der Legende
  scale_fill_manual(values = c("#C9DFE6", "#94C0CD", "#4E97AC", "#366978", "#2E5A67")) # Anwendung der BFFP-Farben
```


```{r quiz_scatterplot}
quiz(caption = NULL,
     
question(
    "In welchen Kontinenten beobachten wir extreme Werte, 'Ausreißer'?",
    answer("Afrika und Amerika"),
    answer("Afrika und Eurpa"),
    answer("Afrika und Asien", correct = TRUE),
    answer("Afrika und Ozeanien"),
    correct = "Richtig!",
    incorrect = "Leider falsch: in Afrika und Asien sehen wir einige sehr große Werte, die weit von den anderen Datenpunkten entfernt sind.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen",
    random_answer_order = TRUE
  ),

    question(
    "Aufsteigend von klein nach groß, wie schätzt ihr die Spannbreite der Plastikstückzahl über die Kontinente hinweg ein?",
    answer(""),
    answer("Ozeanien, Afrika, Amerika, Europa, Asien"),
    answer("Ozeanien, Europa, Amerika, Afrika, Asien", correct = TRUE),
    answer("Europa, Ozeanien, Amerika, Afrika, Asien"),
    correct = "Richtig!",
    incorrect = "Leider falsch. die gesuchte Reihenfolge ist: Ozeanien, Europa, Amerika, Afrika, Asien.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen",
    random_answer_order = TRUE
  )
)
```

Fügen wir nun das **arithmetrische Mittel pro Kontinent** (als Dreieck gekennzeichnet) und die Standardabweichung (als Strich gekennzeichnet) in die Visualisierung ein. Hattet Ihr den Mittelwert an dieser Stelle erwartet? 

```{r geom_point_n_pieces_bericht_mittelwertsd, exercise = TRUE}
ggplot(data = community, aes(x = continent, y = n_pieces, fill = continent)) + # Initialisierung des ggplots mit Variablen
  ggbeeswarm::geom_beeswarm(size = 3, alpha = 0.5, color = "darkgrey") + # Hinzufügen der Datenpunkte (Scatterplot) inkl. Stylingoptionen
  # Mittelwert hinzufügen
  ggplot2::geom_point(data = community %>% 
      # Berechnung der Mittelwerte pro Kontinent
      dplyr::group_by(continent) %>% 
      dplyr::summarise(mean = mean(n_pieces)), 
      # Zuordnung der Mittelwerte zu der gewünschten Darstellungsform
      mapping = aes(x = continent, y = mean), 
      size = 3, color = "#366978", shape = 17) + 
  # Standardabweichung hinzufügen
  ggplot2::geom_errorbar(data = community %>%
      # Berechnung der Mittelwerte und Standardabweichung pro Kontinent
      dplyr::group_by(continent) %>%
      dplyr::summarise(mean = mean(n_pieces), sd = sd(n_pieces)) %>%
      dplyr::mutate(ymin = mean - sd, ymax = mean + sd),
      # Zuordnung der Standardabweichung zu der gewünschten Darstellungsform
      mapping = aes(x = continent, y = mean, ymin = ymin, ymax = ymax),
      color = "darkred", width = 0.1) +
  labs(
    title = "Die Anzahl gesammelter Plastikstücke von 'Break Free From Plastic' ..." ,
    subtitle = "... unterscheidet sich nach Kontinent.",
    y = "Anzahl gefundener Plastikstücke",
    x = "Kontinent",
    caption = glue::glue("n = {nrow(community)}\n Einige Ausreißer wurden zur Lesbarkeit des Graphen ausgeklammert. \nDatenquelle: TidyTuesday und BFFP")) + # Festlegung der Achsenbezeichungen, Überschriften und Titel
  theme_minimal() + # Festlegung des Layout-Designs  
  theme(legend.position="none") + # Ausblenden der Legende
  scale_fill_manual(values = c("#C9DFE6", "#94C0CD", "#4E97AC", "#366978", "#2E5A67")) # Anwendung der BFFP-Farben
```

```{r quiz_Mittelwert}
quiz(caption = NULL,
  question(
    "Wie gut bring der Mittelwert die Verteilung der in den verschiedenen Ländern gesammelten Plastikstücken auf den Punkt?",
    answer("Gut: er ist einfach zu interpretieren"),
    answer("Gut: er passt visuell gut in die Punktewolke."),
    answer("Nicht so gut: nur wenige Beobachtungen sind größer, Ausreißerwerte haben eine großen Einfluss. ", correct = TRUE),
    answer("Nicht so gut: genau die selbe Anzahl Plastikstücke wurde in keinem Land gesammelt."),
    correct = "Richtig!",
    incorrect = "Leider falsch: der Mittelwert wird stark von Ausreißern beeinflusst.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen",
    random_answer_order = TRUE
  ))
```


#### Statistische Kennzahlen
Obwohl er das wohl am häufigsten genutzte statistische Maß ist: Das arithmetische Mittel (auch: Mittelwert) darf **nur für metrisch skalierte Variablen** berechnet werden (!) und muss aufgrund der fehlenden **Robustheit gegenüber Ausreißern** oft genauer betrachtet werden, um aus den Daten keine falschen Schlüsse zu ziehen. Klarer wird das, wenn der Mittelwert mit anderen statistischen Kennzahlen betrachtet wird. Hierfür nutzen wir **`dplyr::group_by()` und `dplyr::summarize()`**, um die Kennzahlen je Kontintent zu berechen und ein kompaktes R-Objekt (ein `tibble`) zu erstellen, das wir abspeichern und weiterverwenden können. Ausführlicher besprechen wir diese Befehle in der Einheit **Datentransformation**.

```{r ueberblick_statistische_kennzahlen, exercise = TRUE}
# Tabelle mit statistischen Kennzahlen
community %>%
  group_by("Kontinent" = continent) %>%
  summarise("Anzahl Beobachtungen" = n(),
         "Anzahl Events" = sum(n_events),
         "Anzahl Freiwillige" = sum(n_volunteers),
         "Mittelwert" = mean(n_pieces),
         "Standardabweichung" = sd(n_pieces),
         "Median" = median(n_pieces),
         "Quartil (25%)" = quantile(n_pieces, .25),
         "Quartil (75%)" = quantile(n_pieces, .75),
         "Interquartilsabstand (IQR)" = IQR(n_pieces),
         "Spannweite" = max(n_pieces) - min(n_pieces))
```

Die Standardabweichung hat die **gleiche Einheit** wie unsere Variable (also ein Plastikstück) und gibt die **Streuung um den Mittelwert** an. Hohe Werte weisen auf die Existenz von Ausreißern hin. Für Asien ist die Standardabweichung beispielsweise mit 29424 doppelt so groß wie der Mittelwert. Ein klares Indiz dafür, dass es extreme Beobachtungswerte gibt.  

```{r quiz_standardabweichung}
quiz(caption = NULL,
  question("Warum gibt R für die Standardabweichung für Ozeanien (eng. Oceania) 'NA' aus?",
    answer("Weil keine Plastikstücke gefunden wurden."),
    answer("Weil Ozeanien nur drei Stück Plastik registriert hat."),
    answer("Weil nur ein Land in Ozeanien mitgemacht hat.", correct = TRUE),
    answer("Kann eigentlich nicht sein. Deutet auf einen Fehler hin."),
    correct = "Richtig!",
    incorrect = "Leider falsch: In Ozeanien hat nur ein Land mitgemacht, weshalb es zwischen einzelnen Beobachtungen auf Länderebene natürlich keine Standardabweichung geben kann.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen",
    random_answer_order = TRUE
  )
)
```

Der **Median** stellt die **wahre Mitte der Verteilung** dar. Er ist gleichzeitig auch das 50%-Quantil. Stellt Euch die Beobachtungen als Punkte (also die einzelnen Länder mit ihrer Plastikstückanzahl) der Reihe nach aufsteigend vor. Das 50%-Quantil, der Median, ist die Beobachtung, die diese Reihe genau in zwei Hälften teilt: In Asien haben 17 Länder an **Break Free From Plastic** teilgenommen. Die Anzahl an Plastikstücken des neunte Land in der imaginären Aufreihung ist der Median. Hier beträgt er 3.459 Plastikstücke, soviel wie in China gesammelt wurden. Bei hohen Unterschieden zwischen Mittelwert und Median ist davon auszugehen, dass Ausreißer die Werte verzerren.

Besonders häufig wird zudem das **25%-Quantil** und das **75%-Quantil** genutzt. In Asien wäre das die Plastikstückanzahl von Japan, mit 84 Stücken dem fünften Land in aufsteigender Reihenfolge, und Malaysia, mit 4.880 Plastikstücken dem dreizehnten Land in der Reihe. In Asien fällt es besonders leicht Quantile zu erklären, da wir eine *ungerade* Anzahl an Beobachtungen haben sind das 25%, 50%, und 75%-Quantil die Ausprägungen von konkreten Beobachtungen. Hätten wir eine *gerade* Anzahl, zum Beispiel 18 Länder, dann wären diese Quantilswerte die Mittelwerte zwischen Beobachtungen. Für den Median zum Beispiel der Mittelwert aus dem Land an Position 9 und 10. 


#### Boxplots und ihre besondere Funktionsdualität
**Boxplots** stellen die Verteilung von Variablen inklusiver wichtiger statistischer Eigenschaften dar. Sie fassen die **fünf Punkte der Verteilung (Minimum, 25%-Quartil, Median, 75%-Quartil, Maximum)** zusammen und geben damit einen sehr guten Überblick über Daten. Deshalb fügen wir sie nun zum Graphen hinzu: 

```{r graphik_bericht_inkl_boxplot, exercise = TRUE}
# Erstellung eines Boxplots mit Punktewolke zur Anzahl gesammelter Plastikstücke pro Kontinent
ggplot(data = community, aes(x = continent, y = n_pieces, fill = continent)) + # Initialisierung des ggplots mit Variablen
  ggbeeswarm::geom_beeswarm(size = 3, alpha = 0.5, aes(color=continent)) + # , color = "darkgrey") # Hinzufügen der Datenpunkte (Scatterplot) inkl. Stylingoptionen zur Positionierung, Punktegröße, Transparenz und Farbe zur Verdeutlichung der Anzahl
  geom_boxplot(alpha = 0.6, width=0.1, position= position_nudge(x = -0.3)) + # Hinzufügen des Boxplots
  coord_cartesian(ylim = c(0, median(community$n_pieces) + 2 * IQR(community$n_pieces))) + # Festlegung der Achsenlänge der y-Achse abhängig von Median und Standardabweichung
  labs(
    title = "Auch die Anzahl gesammelter Plastikstücke von 'Break Free From Plastic' ..." ,
    subtitle = "... unterscheidet sich nach Kontinent.",
    y = "Anzahl gefundener Plastikstücke",
    x = "Kontinent",
    caption = glue::glue("n = {nrow(community)}\n Einige Ausreißer wurden zur Lesbarkeit des Graphen ausgeklammert. \nDatenquelle: TidyTuesday und BFFP")) + # Festlegung der Achsenbezeichungen, Überschriften und Titel
  theme_minimal() + # Festlegung des Layout-Designs  
  theme(legend.position="none") + # Ausblenden der Legende
  scale_fill_manual(values = c("#C9DFE6", "#94C0CD", "#4E97AC", "#366978", "#2E5A67")) + # Anwendung der BFFP-Farben
  scale_color_manual(values = c("#C9DFE6", "#94C0CD", "#4E97AC", "#366978", "#2E5A67")) 
```

Die Außenkanten der Box sind das 25%- und 75%-Quantil. Die Länge der Box gibt den **Interquartilsabstand** (IQR) an und enthält **50% der Beobachtungen**. Der Strich innerhalb der Box markiert den **Median**. Die **"Antennen" des Boxplots** (engl.: whiskers) erweitern die Box um das 1,5fache des Interquartilsabstand. Alle Punkte, die außerhalb der Whisker liegen, sind Ausreißer.

```{r quantile}
quiz(caption = NULL,
 question("Was trifft nicht auf das 50%-Quantil zu?",
    answer("Auch als Median bekannt."),
    answer("Nicht so sensibel Ausreißern gegenüber wie das arithmetische Mittel."),
    answer("Entspricht stets dem arithmetischem Mittel.", correct = TRUE),
    answer("50% aller Werte sind kleiner (gleich) diesem Wert."),
    correct = "Richtig!",
    incorrect = "Leider falsch: Median und Mittelwert können bei symmetrischen Verteilungen identisch sein, in der Regel unterscheiden sie sich aber.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen",
    random_answer_order = TRUE
  ),
 
 question("Was trifft auf Boxplots zu?",
    answer("Wir können daraus den Mittelwert ablesen."),
    answer("Alle Beobachtungen liegen innerhalb der 'Box'."),
    answer("Sie fassen 5 Punkte einer Verteilung zusammen.", correct = TRUE),
    answer("Boxplots kann man auch auf nominalskalierte Variablen wie Kontinente anwenden."),
    correct = "Richtig!",
    incorrect = "Leider falsch: Boxplot ist nur auf mindestens ordinalskalierte Variablen anwendbar und geben den Median aus. Ausreißer können auch außerhalb der Whisker abgetragen sein.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen",
    random_answer_order = TRUE
  ),
 
  question("Was sind die fünf Punkte einer Verteilung?",
    answer("Minimum", correct = TRUE),
    answer("25%-Quantil", correct = TRUE),
    answer("Mittelwert"),
    answer("Median", correct = TRUE),
    answer("75%-Quantil", correct = TRUE),
    answer("Maximum", correct = TRUE),
    correct = "Richtig!",
    incorrect = "Leider falsch: Boxplot ist nur auf mindestens ordinalskalierte Variablen anwendbar und geben den Median aus. Ausreißer können auch außerhalb der Whisker abgetragen sein.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen",
    random_answer_order = TRUE
  )
)

```

Fassen wir kurz zusammen: Wir wissen nun, dass im Datensatz einige Ausreißer enthalten sind. Daher müssen wir in der statistischen Zusammenfassung den Median und nicht das arithmetische Mittel nutzen und auf den Achsenabschnitten in graphischen Darstellungen die extremen Werte ausklammern. Bei der Interpretation der Daten müssen wir die Aggregationsebene betrachten: Wir können hier lediglich **zwischen den Ländern vergleichen** und müssen beachten, warum diese Schwankungen existieren. So weichen auch die Anzahl durchgeführter Events und die Anzahl involvierter Freiwilliger stark voneinander ab. Wie genau diese Unterschiede zu werten sind und ob das auf Basis der Daten möglich ist, müssen wir noch herausfinden.


#### Fragen mit Daten beantworten
"Wie viel Plastik wurde durchschnittlich je Kontinent gesammelt?" - so lautete unsere Daten-Frage. Diese können wir nun beantworten. Nach der Datenexploration wissen wir unter anderem, dass wir dem allgemeinsprachlichen "durchschnittlich" mit einem Vergleich der Mediane begegnen werden. Betrachtet nun nochmals das Diagramm oben und antwortet auf die Quizfragen. 

```{r inhaltliche_interpretation}
quiz(caption = NULL,
  question("Welcher Kontinent hat im Mittel am meisten Plastikstücke gesammelt?",
    answer("Afrika"),
    answer("Nord- und Südamerika"),
    answer("Asien", correct = TRUE),
    answer("Das kann nicht aus dem Schaubild abgelesen werden."),
    correct = "Richtig!",
    incorrect = "Leider falsch: Asien hat am meisten Plastikstücke gesammelt.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen",
    random_answer_order = TRUE
  ),
  
  question("Welcher Kontinent hat im Mittel am wenigsten Plastikstücke gesammelt?",
    answer("Afrika"),
    answer("Nord- und Südamerika"),
    answer("Asien"),
    answer("Europa", correct = TRUE),
    correct = "Richtig!",
    incorrect = "Leider falsch: Europa hat im Mittel am wenigsten Plastikstücke gesammelt.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen",
    random_answer_order = TRUE
  ),
  
  question(
    "Warum ist der Median unter anderem in Asien so viel kleiner als der Mittelwert?",
    answer("Weil in Asien die meisten Länder sich beteiligt haben."),
    answer("Weil es einige wenige, extreme Beobachtungen gab.", correct = TRUE),
    answer("Weil dies eine Eigenschaft des Medians ist."),
    answer("Das kann eigentlich nicht sein - es deutet auf einen Fehler hin."),
    correct = "Richtig!",
    incorrect = "Leider falsch: Der Mittelwert wird von Extremwerten stark beeinflusst. Der Median ist im Vergleich wesentlich robuster, weshalb er für Asien kleiner ausfällt.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen"
  ),
  
  question(
    "In welchem Kontinent ist der Interquartilsabstand am größten?",
    answer("Ozeanien"),
    answer("Afrika", correct = TRUE),
    answer("Asien"),
    answer("Amerika"),
    correct = "Richtig!",
    incorrect = "Leider falsch: In Afrika ist die 'Box' am längsten, das heißt hier gibt eine recht große Streuung der mittleren 50% der Verteilung.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen"
    )
)

```

Nina: eventuell in Grundlagen der Statistik (sehr lang sonst)

#### Beziehungen zwischen Variablen
Bisher haben wir uns vorallem der **univariaten** (= eine Variable) Verteilung von Plastikstücken gewidmet. Nun möchten wir die Daten weiter nutzen, um **bivariat** (= zwei Variablen) herauszuarbeiten: Welche Faktoren beeinflussen möglicherweise die Unterschiede in der Anzahl an Plastikstücken, die gesammelt wurden? Vielleicht die Zahl an Events?

```{r scatter_plot_n_events}
# Optional: Erstellung eines Punktediagramms mit der Anzahl gesammelter Plastikstücke pro Kontinent
ggplot(data = community, aes(n_events, n_pieces, label = country)) + # Initialisierung des ggplots mit Variablen
  geom_point(position = position_jitter(seed = 3), size = 3, alpha = 0.5, color = "darkgrey") + # Hinzufügen der Datenpunkte (Scatterplot) inkl. Stylingoptionen zur Positionierung, Punktegröße, Transparenz und Farbe
  geom_vline(xintercept=mean(community$n_events), color= "darkgray") +
  geom_hline(yintercept=mean(community$n_pieces), color= "darkgray") +
  geom_line(stat="smooth", method = "lm", colour = "darkred", alpha= 0.5, size=1.5) + # Trendlinie hinzufügen
  #stat_smooth(colour = "darkred", method = "lm", alpha=0.6) + # Trendlinie hinzufügen
  coord_cartesian(xlim = c(0, median(community$n_events) + 2 * IQR(community$n_events)), ylim = c(0, median(community$n_pieces) + 2 * IQR(community$n_pieces))) + # Festlegung der Achsenlänge der y-Achse abhängig von Median und Interquartilabstand
  geom_text(size = 2) + 
  labs(
    title = "Anzahl gesammelter Plastiksstücke bei 'Break Free From Plastic' ..." ,
    subtitle = "... in Abhängigkeit von der Eventanzahl.",
    x = "Events",
    y = "Anzahl gefundener Plastikstücke",
    caption = glue::glue("n = {nrow(community)}\n Einige Ausreißer wurden zur Lesbarkeit des Graphen ausgeklammert. \nDatenquelle: TidyTuesday und BFFP")) + # Festlegung der Achsenbezeichungen, Überschriften und Titel
  theme_minimal() # Festlegung des Layout-Designs
```

In diesem Scatterplot haben wir zwei Hilfslinien abgetragen, welche jeweils den Mittelwert erfassen. Durch die Hilflinien entstehen 4 Quadranten. Würden im Quadranten links unten und rechts oben die meisten Punkte liegen, würde ein positiver statistischer Zusammenhang vorliegen. Denn dies würde bedeuten: je größer die Anzahl an Events desto größer oftmals auch die Anzahl an gesammelten Plastikstücken. Im Graphen sehen allerdings, dass vor allem links unten recht viele Punkte geballt auftreten. Die meisten Länder haben tatsächlich nur ein oder zwei Events veranstaltet. Dies bedeutet auch, es gibt in der Variable `n_events` nur wenig Variation. Der Korrelationskoeffizient, der den statistischen Zusammenhang zwischen zwei metrisch skalierten Variablen erfasst, beträgt `r cor(community$n_pieces, community$n_events)`. Er ist zwar positiv, aber sehr nah bei null. Die Trendlinie im Graphen ist nahezu waagerecht. 

```{r scatterplot_interpretation}
quiz(caption = NULL,
  question("Welche Art Zusammenhang vermutet ihr?",
    answer("eindeutig kein Zusammenhang"),
    answer("eindeutignegativ"),
    answer("eindeutig positiv"),
    answer("Das kann nicht aus dem Schaubild nicht eindeutig ablesen." , correct = TRUE),
    correct = "Richtig!",
    incorrect = "Leider falsch: Mit Augenmaß ist kein eindeutiger Zusammenhang ersichtlich.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen",
    random_answer_order = TRUE
  ),
  
  question(
    "Welche Anzahl an Events beobachten wir am meisten?",
    answer("4"),
    answer("1", correct = TRUE),
    answer("3"),
    answer("2"),
    correct = "Richtig!",
    incorrect = "Leider falsch: Die meisten Länder haben genau ein Event veranstaltet.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen"
    )
)
```


Sylvi: ggf. kürzen
Wenn wir uns das Punktediagramm, dass die Anzahl an Plastikstücken der Anzahl an Freiwilligen gegenüberstellt. Ist ein etwas deutlicherer Zusammenhang erkenntlich. Der Korrelationskoeffizient bringt diesen statistischen Zusammenhang auf den Punkt in einer Zahl. Berechnet ihn für diese beiden Variablen.

```{r korrelation_pieces_volunteers, exercise=TRUE}
cor(community$n_pieces, community$n_volunteers)
```

0.81 bestätigt, dass wir einen positiven und recht starken statischen Zusammenhang zwischen der Anzahl an Plastikstücken und Freiwilligen beobachten. Beachtet, der Korrelationskoeffizient bietet keinerlei Möglichkeit einer kausalen Aussage. Weder unser Diagramm noch die der Koeffizient lassen den Schluss zu, dass alleinig mehr Freiwillige zu mehr gesammelten Plastikstücken führen.

```{r scatter_plot_n_volunteers}
# Optional: Erstellung eines Punktediagramms mit der Anzahl gesammelter Plastikstücke pro Kontinent
ggplot(data = community, aes(n_volunteers, n_pieces, label = country)) + # Initialisierung des ggplots mit Variablen
  geom_point(position = position_jitter(seed = 3), size = 3, alpha = 0.5, color = "darkgrey") + # Hinzufügen der Datenpunkte (Scatterplot) inkl. Stylingoptionen zur Positionierung, Punktegröße, Transparenz und Farbe
  geom_vline(xintercept=mean(community$n_volunteers), color= "darkgray") +
  geom_hline(yintercept=mean(community$n_pieces), color= "darkgray") +
  geom_line(stat="smooth", method = "lm", colour = "darkred", alpha= 0.5, size=1.5) + # Trendlinie hinzufügen
  coord_cartesian(xlim = c(0, median(community$n_volunteers) + 3 * IQR(community$n_volunteers)), ylim = c(0, median(community$n_pieces) + 3 * IQR(community$n_pieces))) + # Festlegung der Achsenlänge der y-Achse abhängig von Median und Interquartilabstand
  geom_text(size = 2) + 
  labs(
    title = "Anzahl gesammelter Plastiksstücke bei 'Break Free From Plastic' ..." ,
    subtitle = "... in Abhängigkeit von der Freiwilligenzahl",
    x = "Anzahl Freiwillige",
    y = "Anzahl gefundener Plastikstücke",
    caption = glue::glue("n = {nrow(community)}\n Einige Ausreißer wurden zur Lesbarkeit des Graphen ausgeklammert. \nDatenquelle: TidyTuesday und BFFP")) + # Festlegung der Achsenbezeichungen, Überschriften und Titel
  theme_minimal() # Festlegung des Layout-Designs
```

Was nehmen wir nehmen wir aus dieser bivariaten Analyse mit? Die Zahl an Freiwilligen scheint ein bedeutender Faktor zu sein. Diese könnte durch mehr Events hervorgerufen werden oder einfach für an sich der wichtige Faktor sein. Warum genau, darauf kann der Korrelationskoeffizient keine Antwort geben. Den Fokus darauf zu legen, viele Freiwillige zu erreichen wäre ein Feedback, das in die Community zurück gespielt werden könnte, um die nächsten Runden von **"Break Free from Plastic"** noch erfolgreicher zu machen. Ggf. könnte die Organisation sich bei den Ländern, die besonders viele Freiwilligen hatten, nach ihren Best Practices erkundigen und diese in der gesamten Organisation teilen.


### Und jetzt Ihr
Diese Woche möchten wir die Präsenzzeit nutzen, um die folgenden Übungen zu besprechen. Ergänzt unseren Input gerne mit zudem mit Euren **Ideen, Fragen, Anregungen oder Kommentaren**. Es ist nicht schlimm, falls diese Woche noch gar nichts (komplexes) klappt, da wir das Gelernte in den nächsten Wochen wiederholen und vertiefen werden.

1. Überlegt: Mit welchen Daten und Datenanalysen könnte die Frage "Wie erfolgreich war der Audit?" noch beantwortet werden? Wie könnte eine Visualisierung oder eine zusammenfassende Statistik dabei helfen? Skizziert Eure Fragen gerne schriftlich.

2. Versucht, das zugehörige [**R Markdown: 05_ErsteDatenanalysenInR **](https://correlcloud.org/index.php/s/56cTMCbMPbYLEya){target="_blank"} zum Laufen zu bringen und es nachzuvollziehen.

3. In der ersten Einheit haben wir uns bei der Visualisierung vor allem der **n_pieces Variable** gewidmet. Nun blicken wir auf die **n_volunteers**: Wie sehr unterscheiden sich die Freiwilligenzahlen nach Kontinenten? Erstellt in dem heruntergeladenen RMarkdown ein **Punktediagramm** (Scatterplot) mit dem Datensatz `community` für diesen Blickwinkel auf den Erfolg der "Break Free from Plastik" Aktion. Die Graphik soll `n_volunteers`, die **Anzahl der Freiwilligen** auf der y-Achse und die **Kontinente** auf der x-Achse zeigen. 
*Hinweis: Versucht dazu im  RMarkdown in der finalen Version der Graphik die entsprechenden Variablen auszutauschen (und sonst erstmal nichts).*

4. Interpretiert die Graphik. Was nehmt Ihr daraus mit?


### Zusätzliche Ressourcen
- Die kostenlosen Kurse des [Statistischen Bundesamts](https://www.destatis.de/DE/Service/Statistik-Campus/E-Learning/eLearning-statistik.html;jsessionid=63AE25DDABD8853990FBE83F354C8911.live722?nn=206328){target="_blank"}
- Stocker T. C. und Steinke I. (2017): Statistik – Grundlagen und Methodik [verfügbar z.B. hier](https://www.beck-shop.de/stocker-steinke-de-gruyter-studium-statistik/product/32926361){target="_blank"}
- [R for Data Science (engl.)](https://r4ds.had.co.nz/){target="_blank"}
- [Statistics Fundamentals in R](https://app.dataquest.io/course/statistics-fundamentals-r){target="_blank"} auf DataQuest (engl.)
- [Lernvideos](https://www.youtube.com/watch?v=RRIsBFW8ovc){target="_blank"} zur Inferenzstatistik (dt.)