## Erste Datenanalysen in R

![*Video: Erste Datenanalysen in R (30min)*](https://youtu.be/58i2_o-zDug)
*Empfehlung: Schaut Euch das Video in zwei Teilen an. Bis 18:42 geht es um Visualisierung, danach um statistische Kennzahlen.*

### Kernaussagen
#### Grundlagen der Datenanalyse
- Konzeptionell sollten wir uns von **Fragen zur Exploration, möglichen Plausibilitätschecks und Fallentscheidungen** leiten lassen, die während der Analyse beantwortet werden
- Bei einer Datenanalyse nutzen wir zunächst niedrigschwellige **tabellarische Formate** wie `summary()` und `str()`, um uns einen Überblick über die Daten zu verschaffen
- Danach helfen uns **einfache Datenvisualisierungen**, die Ausprägungen von Variablen zu untersuchen (und Extremwerte zu identifizieren)
- Um weitere Operationen durchführen zu können, berechnen wir im Anschluss **statistische Kennzahlen**, Lage- und Verteilungsparameter, die für uns spannende Informationen enthalten und die Grundlage für weitere Analysen bilden

#### Visuelle Exploration
- **`ggplot2`** ist ein Paket für vielseitige **Graphiken** in R
- Die wichtigsten Schichten (Bestandteile) eines ggplots sind: 
    1. `data` - der **Datensatz**
    2. `aes()` - die **"ästhetischen Attribute"** wie die x- oder y-Achse und Darstellungsoptionen
    3. `geom_*()` - die **geometrische Form**, mit welcher die Werte dargestellt werden, z.B. geom_point() für Punktediagramme oder geom_bar() für Bardiagramme
- Einzelne Bestandteile werden mit einem **"+" verknüpft** 

Im Kapitel "Datenvisualisierung" lernt Ihr noch mehr Optionen zur Datenvisualisierung in R kennen. 

#### Statistische Kennzahlen
- Mittels statistischer Kennzahlen lassen sich **Datensätze zusammenfassen** und Fragen an den Datensatz beantworten
- Besonders oft werden folgende Funktionen genutzt: 
    - `min()`: **minimale Ausprägung** einer Variablen
    - `max()`: **maximalen Ausprägung** einer Variablen
    - `median()`: **Median**, der "wahre" Mittelpunkt (50% der Ausprägungen sind kleiner oder größer)
    - `mean()`: arithmetische Mittel, Durchschnitt oder schlicht **Mittelwert**
    - `var()`: **Varianz**, die Streuung um den Mittelwert
    - `sd()`: **Standardabweichung**, ein standardisiertes Maß für die Streuung um den Mittelwert (auch: mittlere Abweichung)
    - `n()`: **Anzahl** bzw. absolute Häufigkeiten der Ausprägungen
    - `sum()`: **Summe** numerischer Variablen.
- Darüber hinaus möchten wir schon folgende **`tidyverse`** folgende Operationen hervorheben:
    - `dplyr::summarize()` - **Zusammenfassung von Werten** zur Vereinfachung des Informationsgehalts
    - `dplyr::group_by()` - **Gruppierung von Zielen** (Beobachtungen) nach Kriterien
- Diese sind eine Art **Power-Duo**. Denn mit `dplyr::group_by()` & `dplyr::summarize()` können statistische Kennzahlen **pro Variablenkategorie** (z.B. Land) ausgegeben werden.
- Verknüpft werden Operationen von *`dplyr`* mit dem **Pipe-Operator "%>%"** (zu dt. Rohrbetreiber), der eine ähnliche Funktion wie das "+" in `ggplot2` erfüllt.

Im Kapitel "Datenbereinigung" lernt Ihr noch mehr Funktionen des tidyverse in R kennen. 

Für diese Lektion benötigt Ihr also zwei Packages: `dplyr`und `ggplot2` (beide Teil des `tidyverse`)
```{r pakete_ersteanalysen, exercise = TRUE}
# install.packages("dplyr")
# install.packages("ggplot2")
library(dplyr)
library(ggplot2)
```

### Quiz
```{r quiz_ersteanalyseninr}
quiz(caption = NULL,
  question("Welche Aussagen sind wahr?",
    answer("Es ist ausreichend statistische Kennzahlen zu berechnen, um Aussagen über die Bedeutung erhobener Daten zu treffen."),
    answer("Es ist ausreichend Visualisierungen zu erstellen, um Aussagen über die Bedeutung erhobener Daten zu treffen."),
    answer("Kontext ist bei rigoroser Datenanalyse nicht so wichtig."),
    answer("Die Berechnung statistischer Kennzahlen, die Visualisierung und die Kontextualisierung sind eine wichtige Grundlage (!) für die Interpretation von Daten und komplexere Analysen.", correct = TRUE),
    correct = "Richtig!",
    incorrect = "Leider falsch. Die Berechnung statistischer Kennzahlen, die Visualisierung und die Kontextualisierung sind eine wichtige Grundlage (!) für die Interpretation von Daten und komplexere Analysen.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen"
  ),
  question("Lageparameter sind...",
    answer("Modus - die am häufigsten beobachtete Ausprägung", correct = TRUE),
    answer("Median - die wahre Mitte der Ausprägungen", correct = TRUE),
    answer("Mittelwert - der Durchschnitt", correct = TRUE),
    answer("Maximum - der höchste Wert"),
    answer("Minimum - der niedrigste Wert"),
    correct = "Richtig!",
    incorrect = "Leider falsch: Mit Maximum und Minimum berechnen wir lediglich die Spannbreite, die selbst ein Streuungsparameter ist.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen"
  ),
  question("Der Mittelwert ist robust gegen Ausreißer.",
    answer("Wahr"),
    answer("Unwahr", correct = TRUE),
    correct = "Richtig!",
    incorrect = "Leider falsch: Der Mittelwert kann durch Ausreißer stark verzerrt werden. Robuster ist der Median.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen"
  ),
  question("Der Mittelwert der Zufallsvariable betrögt 5, die Spannbreite 10 und die Standardabweichung 2. Um wie viel weichen Beobachtungen im Mittel von dem Wert 5 ab?",
    answer("2", correct = TRUE),
    answer("5"),
    answer("10"),
    correct = "Richtig!",
    incorrect = "Leider falsch: Die Standardabweichung sagt aus, um wie viel im Mittel eine Beobachtung von dem Mittelwert abweicht (hier 2).",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen"
  ),
  question("Mit dem Package ggplot2 können...",
    answer("Daten visualisiert werden.", correct = TRUE),
    answer("Statistische Kennzahlen und Übersichtstabellen berechnet werden."),
    answer("Daten importiert werden."),
    answer("Daten bereinigt werden."),
    correct = "Richtig! Die Datenbereinigung und die Berechnung von statistischen Kennzahlen und Übersichtstabellen erfolgen mit dplyr. Für den Import gibt es ganz viele Möglichkeiten, aber dazu in späteren Kapiteln mehr...",
    incorrect = "Leider falsch: Visualierungen erstellen wir u.a. mit ggplot2. Die Datenbereinigung und die Berechnung von statistischen Kennzahlen und Übersichtstabellen erfolgen mit dplyr. Für den Import gibt es ganz viele Möglichkeiten, aber dazu in späteren Kapiteln mehr...",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen"
  )
)
```

### Interaktive Übung

#### Schritt 1: Fragen stellen

Am Anfang einer Datenanalyse steht etwas, dass zunächst gar nichts mit Daten zu tun haben muss: eure Frage. Was sind Fragen, die euch in eurer Organisation umtreiben?

In dieser Einheit kehren wir zurück zu **"Break Free From Plastic"**. Diese Bewegung organisiert unter anderem einen [Brand audit](https://www.breakfreefromplastic.org/brandaudit2021/){target="_blank"} für den in vielen Ländern Freiwillige Plastikstücke sammeln und diese kategorisieren (nach Plastikart und Firma). Ziel ist es große Firmen in die Verantwortung zu nehmen, dass die Verschmutzung durch Plastik beendet wird und insbesondere Einwegplastik reduziert wird. In der Evaluation dieser Audits kommen sicherlich viele Fragen auf. In dieser Einheit möchten wir uns exemplarisch dieser Frage widmen: Wie erfolgreich war der Audit?


#### Wie können wir diese Frage mit den Daten beantworten?

Hierfür müssen wir unsere qualitative Frage in eine quantitative Frage umwandeln, die dann auch mit Daten beantwortbar ist. In dieser Einheit operationalisieren wir die Frage nach dem Erfolg so:

  1. Wie viel Plastik wurde insgesamt gesammelt? <br>
  2. Wie viel Plastik wurde durchschnittlich je Kontinent gesammelt? <br>
  3. Welche Faktoren beeinflussen möglicherweise diese Unterschiede? <br>

Dies sind Fragen, die wir anhand der Variablen im Datensatz beantworten können. Diese Fragen sind viel spezifischer und können natürlich nicht alle Facetten der urpsrünglichen Frage abdecken. Für eine umfangreiche Evaluation bräuchte es sicherlich noch weitere Fragen - welche fallen Euch ein? Hierauf kommen wir in der Diskussion gern zurück. 

Hier liegt der Datensatz nun schon vor und wir können direkt den einzelnen Fragen Variablen zuordnen. In eurer eigenen Arbeit wird es bei der Übersetzung eurer möglicherweise qualitativen Frage zu einer quantitativen Frage etwas Hin-und-Her geben, bis ein geeigneter Datensatz gefunden wurde.

<!-- #### Vorbereitung: Überblick über die Daten gewinnen -->

Der [Datensatz](https://github.com/rfordatascience/tidytuesday/tree/master/data/2021/2021-01-26){target="_blank"} von **"Break Free From Plastic"** stammt aus den Jahren 2019 und 2020. Da es in dieser Einheit darum geht, in den **Analyse-Spirit** zu kommen und R als Analysetool kennenzulernen, haben wir den Datensatz "Break Free from Plastic" bereits **bereinigt** und in **zwei Datensätze** aufgeteilt: der Community Datensatz (als `community` hinterlegt) enthält alle Variablen, welche für Fragestellungen rundum Community-Perspektive nützlich sind und der Audit Datensatz (als `audit` hinterlegt), umfasst jene Variablen, die für Fragen zur Audit-Perspektive nützlich sind. Da 2020 auch für die Initiative ein besonderes Jahr war, konzentrieren wir uns auf 2019.


Insbesondere bei Datensätzen mit vielen Variablen kann die Funktion **`dplyr::glimpse()`** Euch helfen, zu verstehen, was im Datensatz überhaupt enthalten ist. Der `community` Datensatz enthält geographische und zeitliche Variablen sowie Daten zur gesammelten Plastikmenge, Veranstaltungen und Freiwilligen:
```{r exercise_community, exercise = TRUE}
# Überblick über die Community verschaffen
dplyr::glimpse(community)

```

```{r quiz_kurzstatistik}
quiz(
  caption = "",
  
  question(
    "Wie viele Variablen hat der `community`-Datensatz?",
    answer("Das kann man anhand des Outputs nicht sagen."),
    answer("51"),
    answer("5", correct = TRUE),
    answer("7"),
    correct = "Richtig!",
    incorrect = "Leider falsch: 5 Variablen sind enthalten.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen",
    random_answer_order = TRUE
  ),
  
  question(
    "Welche Variablen gibt die Anzahl an gesammelten Plastikstücken an?",
    answer("Das kann man anhand des Outputs nicht sagen."),
    answer("n_volunteers"),
    answer("n_pieces", correct = TRUE),
    answer("n_events"),
    correct = "Richtig!",
    incorrect = "Leider falsch: n_pieces gibt die Anzahl an Plastikstücken, die in einem Land gesammelt wurden an.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen",
    random_answer_order = TRUE
  )

  )

```


<!-- Schaut Euch nun zur Info an, welche Variablen im `audit`-Datensatz enthalten sind. -->
<!-- ```{r exercise_audit, exercise = TRUE} -->
<!-- # Euer Code hier -->
<!-- ``` -->

#### Datenexploration: Daten kennenlernen und plausibilisieren 

Nun kennen wir den Grundaufbau des Datensatzes schon und möchten die Variablen, die für unsere Fragestellungen interessant sind näherkennen lernen und sie plausibilisieren. Hier starten wir mit `base::summary()`.

```{r summary_community}
# Zusammenfassung anzeigen lassen
base::summary(community)
```

Wir sehen, dass die Variablen, die Spalten in unserem Datensatz unterschiedliche Formate haben. `continent` und `country` haben die Class "character", weil sie aus Text/ Buchstaben bestehen. Statistisch gesehen sind sie ein *nominal skalierte* Variablen, da sie Kategorien sind, ohne Ranking und ohne numerischen Wert. Alle anderen Variablen `n_...` sind *metrisch skalierte* Variablen, wir können sie der Größe nach sortieren und mit ihnen ganz natürlich rechnen. Zwar nicht in unserem Datensatz aber zur Vollständigkeit: es gibt auch noch ordinal skalierte Variablen, z.B. Schulnoten, diese haben eine Rangreihenfolge, die Abstände zwischen den Rängen können wir aber nicht sinnvoll interpretieren. Es ist wichtig sich dieser Skalenniveaus bewusst zu sein, um die richtigen statistischen Kennzahlen für eine Variable zu finden. 

Nina: 
- Finde es bisher richtig gut! Gerne das auch nochmal in Video erklären :)
- Hier könnten wir noch die Entität ansprechen. "Neben der Skalenebene ist auch die Entitätenebene relevant: ... Wenn Daten aggregiert wurden, müssen wir das bei der Intepretation beachten."
- Wollen wir noch etwas genauer auf den großen Unterschied zwischen Mean vs. Median eingehen oder kommt das später eventuell noch?
- Auch die Quartile sind spannend - ist mir bisher selber noch gar nicht so genau aufgefallen

```{r quiz_plausibilisierung}
quiz(
  caption = "",
  
  question(
    "Was ist der höchste Wert, den die Variable n_pieces annimmt?",
    answer("Das kann man anhand des Outputs nicht sagen."),
    answer("68.5"),
    answer("1.0", correct = TRUE),
    answer("120646.0"),
    correct = "Richtig!",
    incorrect = "Leider falsch: 1 Plastikstück ist der niedrigste Wert.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen",
    random_answer_order = TRUE
  ),
  
  question(
    "Die Spannweite gibt die Differenz zwischen dem größten und dem kleinsten Wert einer Variable an. Wie plausibel findet ihr die Spannweite der Variable n_pieces?",
    answer("Das kann man anhand des Outputs nicht sagen."),
    answer("Viel zu groß."),
    answer("Plausibel", correct = TRUE),
    answer("Viel zu klein"),
    correct = "Richtig! Wir sehen keine negativen Werte und auch die Größenordnung erscheint nicht unplausibel.",
    incorrect = "Leider falsch: Die Spannweite erscheint plausibel: wir sehen keine negativen Werte und auch die Größenordnung ist vorstellbar ",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen",
    random_answer_order = TRUE
  )

  )

```

Ebenso zur Datenexploration gehört die Visualisierung der Rohdaten. Dafür erstellen wir eine Punktediagramm (englisch: Scatterplot), indem wir die Variablen `continent` und `n_pieces` vom Datensatz `community` als `aes()`-Variablen eingeben und R bitten sie als `geom_point`, also als Punkte auszugeben. So sieht der Code für diesen **Scatterplot** aus. Lasst den Code zunächst einfach durchlaufen und versucht zu verstehen, was passiert. In der Lektion 8 *Datenvisualisierung* gehen wir noch genauer darauf ein, wie genau so eine Graphik erstellt wird, hier geht es erst einmal darum, R bei der DataVizMagie zu zusehen. Nehmt Euch einen Moment und beschreibt die Graphik in Euren Worten. Was fällt Euch auf?

```{r geom-point-video, exercise=TRUE}
# Erstellung eines Scatterplots zu der Anzahl an Freiwilligen
ggplot2::ggplot(data = community, aes(x = continent, y = n_pieces)) + # Initialisierung des ggplots mit Variablen
  geom_point(position = position_jitter(width = 0.3),
             size = 3,
             alpha = 0.6) + # Hinzufügen der Datenpunkte (Scatterplot) inkl. Layoutoptionen zur Positionierung, Punktegröße und Transparenz
  labs(
    title = "Die Anzahl an gesammelten Plastikstücken bei 'Break Free From Plastic' ..." ,
    subtitle = "... unterscheidet sich nach Kontinent.",
    y = "Anzahl Plastikstücke",
    x = "Kontinent",
    caption = "Datenquelle: TidyTuesday und BFFP"
  ) + # Festlegung der Achsenbezeichnungen, Überschriften und Titel
  theme_minimal() # Festlegung des Layout-Designs
```
Nina: 
- Können wir hier den Plot aus dem Report betrachten? Mit auskommentierter Achsenbegrenzung? Für unseren roten Faden!
- Hier könnte man die Verknüpfung zwischen Spannweite (statistische Kennzahl) und der Visualisierung herstellen
- Wozu macht man Scatterplots und warum machen wir es hier trotzdem?

```{r}
# Optional: Erstellung eines Boxplots mit Punktewolke zur Anzahl gesammelter Plastikstücke pro Kontinent
ggplot(data = community, aes(x = continent, y = n_pieces, fill = continent)) + # Initialisierung des ggplots mit Variablen
  geom_point(size = 3, alpha = 0.5, position = position_jitter(seed = 1, width = .2), color = "darkgrey") + # # Hinzufügen der Datenpunkte (Scatterplot) inkl. Stylingoptionen zur Positionierung, Punktegröße, Transparenz und Farbe zur Verdeutlichung der Anzahl
  geom_boxplot(alpha = 0.6) + # Hinzufügen des Boxplots
  #coord_cartesian(ylim = c(0, median(community$n_pieces) + 0.5 * sd(community$n_pieces))) + # Festlegung der Achsenlänge der y-Achse abhängig von Median und Standardabweichung
  labs(
    title = "Auch die Anzahl gesammelter Plastikstücke von 'Break Free From Plastic' ..." ,
    subtitle = "... unterscheidet sich nach Kontinent.",
    y = "Anzahl gefundener Plastikstücke",
    x = "Kontinent",
    caption = glue::glue("n = {nrow(community)}\n Einige Ausreißer wurden zur Lesbarkeit des Graphen ausgeklammert. \nDatenquelle: TidyTuesday und BFFP")) + # Festlegung der Achsenbezeichungen, Überschriften und Titel
  theme_minimal() + # Festlegung des Layout-Designs  
  theme(legend.position="none") + # Ausblenden der Legende
  scale_fill_manual(values = c("#C9DFE6", "#94C0CD", "#4E97AC", "#366978", "#2E5A67")) # Anwendung der BFFP-Farben
```


```{r quiz_scatterplot}
quiz(
  caption = "",
  
  question(
    "In welchen Kontinenten beobachten wir extreme Werte?",
    answer("Afrika und Amerika"),
    answer("Afrika und Eurpa"),
    answer("Afrika und Asien", correct = TRUE),
    answer("Afrika und Ozeanien"),
    correct = "Richtig!",
    incorrect = "Leider falsch: in Afrika und Asien sehen wir einige sehr große Werte.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen",
    random_answer_order = TRUE
  )

  )

```


**Bis hier hin, bin ich gekommen mit dem skizzieren**

Lasst uns in Asien etwas mehr hineinzoomen und die Verteilung von Plastikstücken, die in asiatischen Ländern gesammelt wurden näher kennenlernen. 
```{r ggplot nur für Asien}

# Min, Max und Median im Scatterplot einfärben -- !? Klappt noch nicht
community<-community %>%
  mutate(color = case_when(
    (n_pieces == min(n_pieces) | n_pieces == max(n_pieces) | n_pieces == median(n_pieces) ) ~ "1",
     TRUE ~ "0"
  ))

ggplot2::ggplot(data = subset(community, continent == "Asien"), aes(y = continent, x = n_pieces, color=color)) + # Initialisierung des ggplots mit Variablen
  geom_point(position = position_jitter(width = 0.9),
             size = 3,
             alpha = 0.6) + # Hinzufügen der Datenpunkte (Scatterplot) inkl. Layoutoptionen zur Positionierung, Punktegröße und Transparenz
  labs(
    title = "Die Anzahl an gesammelten Plastikstücken bei 'Break Free From Plastic'" ,
    x = "Plastikstücke",
    y = "",
    color = ""
    ) + # Festlegung der Achsenbezeichnungen, Überschriften und Titel
  theme_minimal() # Festlegung des Layout-Designs
```


```{r Verteilung als Histogram/ Dotplot}
# Oder als histogram ?
ggplot2::ggplot(data = subset(community, continent == "Asien"), aes(x=n_pieces, fill=stat(x > median(community$n_pieces)))) + # Initialisierung des ggplots mit Variablen
  ggdist::stat_dotsinterval( quantiles = 100) +
 
 # geom_dotplot()  + #aes(y = ..density..)
  #geom_density(color="red", line_type=1) +
  labs(
    title = "Verteilung der Beteiligung an 'Break Free From Plastic' in ..." ,
    #subtitle = "... unterscheidet sich nach Kontinent.",
    y = "Relative Häufigkeit",
    x = "Anzahl Plastikstücke"
    ) + # Festlegung der Achsenbezeichnungen, Überschriften und Titel
  theme_minimal() # Festlegung des Layout-Designs

```

```{r Median einfärben}

```

```{r Boxplot}

ggplot2::ggplot(data = subset(community, continent == "Asien"), aes(x=n_pieces)) + # Initialisierung des ggplots mit Variablen
  geom_boxplot()  + #aes(y = ..density..)
  #geom_density(color="red", line_type=1) +
  labs(
    title = "Verteilung der Beteiligung an 'Break Free From Plastic' in Europa" ,
    #subtitle = "... unterscheidet sich nach Kontinent.",
    #y = "Absolute Häufigkeit",
    x = "Anzahl Freiwilliger"
    ) + # Festlegung der Achsenbezeichnungen, Überschriften und Titel
  theme_minimal() # Festlegung des Layout-Designs

```



```{r Beteiligung in Europa}

community %>%
  filter(continent == "Europa") %>% summary()
  

community %>%
  group_by(continent) %>% summarize(mean=mean(n_volunteers), 
                                    sd_volunteers=sd(n_volunteers),
                                    median = median(n_volunteers))

```



```{r exercise_audit-solution}
# Überblick über den Audit verschaffen
dplyr::glimpse(audit)
```

```{r exercise_audit-check}
grade_this_code()
```
Der **Audit-Datensatz** enthält also - wie der `Community`-Datensatz - die Gesamtplastikmenge, geographische und zeitliche Daten, aber keine Daten zu Veranstaltungen und Freiwilligen. Stattdessen findet Ihr hier Daten zu den Plastikarten.

Nutzt an dieser Stelle gerne auch die anderen Funktionen, die Ihr in den letzten Lektionen kennengelernt habt, um Euch einen Überblick über die beiden bereinigten Datensätze zu verschaffen.

```{r exercise_ueberblick, exercise = TRUE}
# Euer Code hier
```



#### Statistische Kennzahlen 
Nun nutzen wir statistischen Kennzahlen, um mit Hilfe des `audit_plastic`-Datensatz die folgenden Fragen zu beantworten: <br>
  1. Wie viel Plastik wurde insgesamt gesammelt? <br>
  2. Wie viel Plastik wurde durchschnittlich je Kontinent gesammelt? (Analyse innerhalb der Kontinente) <br>
  3. Wie viele Plastikarten wurden gesammelt? <br>

Ihr kennt nun bereits den Befehl **`dplyr::glimpse()`**, mit dem Ihr Euch die Kurzstatistik des Datensatzes anzeigen lassen könnt. Nutzt ihn hier, um die folgenden Fragen zu beantworten.

```{r exercise_summary, exercise = TRUE}
# Euer Code hier
```

```{r exercise_summary-solution}
# Übersicht über Plastik-Audit verschaffen
dplyr::glimpse(audit)
```

```{r exercise_summary-check}
grade_this_code()
```

```{r quiz_kurzstatistik}
quiz(
  caption = "",
  
  question(
    "Wie viele Variablen hat der `audit_plastic`-Datensatz?",
    answer("Das kann man anhand des Outputs nicht sagen."),
    answer("52"),
    answer("12", correct = TRUE),
    answer("7"),
    correct = "Richtig!",
    incorrect = "Leider falsch: 12 Variablen sind enthalten.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen",
    random_answer_order = TRUE
  ),
  
  question(
    "Wie viele Zeilen (Länder) sind im Datensatz?",
    answer("Das kann man anhand des Outputs nicht sagen."),
    answer("2019"),
    answer("52", correct = TRUE),
    answer("13"),
    correct = "Richtig!",
    incorrect = "Leider falsch: 52 Länder sind enthalten.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen",
    random_answer_order = TRUE
  ),
  
  question(
    "Wie viele Kontinente sind im Datensatz?",
    answer("13"),
    answer("3"),
    answer("Das kann man anhand des Outputs nicht sagen.",
      correct = TRUE
    ),
    answer("52"),
    correct = "Richtig!",
    incorrect = "Leider falsch: Um das zu beurteilen, müssen wir noch mehr Rechenoperationen durchführen.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen",
    random_answer_order = TRUE
  )
)
```

Kennzahlen können mittels **`summarize`** auch **einzeln berechnet werden**. Dies hat den Vorteil, dass ein kompaktes R-Objekt entsteht (ein `tibble`), das wir abspeichern und weiterverwenden können. 

```{r summarize_einfuhrung, exercise=TRUE}
# Berechnung von Mittelwert der gesammelten Plastikmenge pro Kontinent
audit %>%
  dplyr::summarize(menge_mittelwert = mean(n_pieces))
```

Eine sehr nützliche Kombination ist: **`dplyr::group_by()` und `dplyr::summarize()`**. Damit können wir erst Daten **gruppieren**, hier zum Beispiel nach Kontinenten, und dann Kennzahlen wie den Mittelwert und die Standardabweichung der gefundenen Plastikstücke pro Kontinent berechnen. 

```{r gruppieren, exercise=TRUE}
# Berechnung von Mittelwert und Standardabweichung pro Kontinent
audit %>%
  dplyr::group_by(continent) %>%
  dplyr::summarize(
    # Mittelwert
    menge_mittelwert = mean(n_pieces),
    #Standardabweichung
    menge_standardabweichung = sd(n_pieces)
  ) 
```

```{r quiz_kennzahlen, echo=FALSE}
quiz(caption = NULL,
     
  question("Welcher Kontinent hat durchschnittlich am meisten Plastikstücke gesammelt?",
    answer("Afrika"),
    answer("Nord- und Südamerika"),
    answer("Asien", correct = TRUE),
    answer("Das kann nicht aus der Tabelle abgelesen werden."),
    correct = "Richtig!",
    incorrect = "Leider falsch: Asien hat am meisten Plastikstücke gesammelt.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen",
    random_answer_order = TRUE
  ),
  
  question("Warum ist die Standardabweichung für Ozeanien (eng. Oceania) 'NA'?",
    answer("Weil keine Plastikstücke gefunden wurden."),
    answer("Weil Ozeanien nur drei Stück Plastik registriert hat."),
    answer("Weil nur ein Land in Ozeanien mitgemacht hat.", correct = TRUE),
    answer("Kann eigentlich nicht sein. Deutet auf einen Fehler hin."),
    correct = "Richtig!",
    incorrect = "Leider falsch: In Ozeanien hat nur ein Land mitgemacht, weshalb es zwischen einzelnen Beobachtungen auf Länderebene natürlich keine Standardabweichung geben kann.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen",
    random_answer_order = TRUE
  )
)
```

Weitere interessante Kennzahlen sind: der **Median (`median()`)** der gesammelten Plastikstücke, die **Anzahl (`n()`)** der Länder und die **Summe (`sum()`)** aller gesammelten Plastikstücke. Ergänzt den Code um diese beiden Kennzahlen. 

```{r gruppieren2, exercise=TRUE}
# Berechnung von Mittelwert und Standardabweichung für Plastikmenge pro Kontinent
audit_plastic %>%
  dplyr::group_by(continent) %>%
  dplyr::summarize(
    # Mittelwert
    menge_mittelwert = mean(grand_total),
    # Standardabweichung
    menge_standardabweichung = sd(grand_total)
    # Hier Euer Code
  )
```

```{r gruppieren2-solution}
# Berechnung statistischer Kennzahlen pro Kontinent
community %>%
  dplyr::group_by(continent) %>%
  dplyr::summarize(
    # Mittelwert
    menge_mittelwert = mean(n_pieces),
    # Standardabweichung
    menge_standardabweichung = sd(n_pieces),
    # Median
    menge_median = median(n_pieces),
    # Anzahl beteiligter Länder
    länder_anzahl = n(),
    # Summe der Plastikmenge
    menge_summe = sum(n_pieces)
  )
```

```{r quiz_kennzahlen2, echo=FALSE}
quiz(
  caption = NULL,
  
  question(
    "Wie viele Länder haben sich in Asien beteiligt?",
    answer("1"),
    answer("11"),
    answer("15"),
    answer("17", correct = TRUE),
    correct = "Richtig!",
    incorrect = "Leider falsch: Es haben sich 17 Länder beteiligt.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen"
  ),
  
  question(
    "Warum ist der Median unter anderem in Asien so viel kleiner als der Mittelwert?",
    answer("Weil in Asien die meisten Länder sich beteiligt haben."),
    answer("Weil es einige wenige, extreme Beobachtungen gab.", correct = TRUE),
    answer("Weil dies eine Eigenschaft des Medians ist."),
    answer("Das kann eigentlich nicht sein - es deutet auf einen Fehler hin."),
    correct = "Richtig!",
    incorrect = "Leider falsch: Der Mittelwert wird von Extremwerten stark beeinflusst. Der Median ist im Vergleich wesentlich robuster, weshalb er für Asien kleiner ausfällt.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen"
  ),
  
  question(
    "Wie viele Plastikstücke wurden in Europa sammelt?",
    answer("204.051"),
    answer("29.579", correct = TRUE),
    answer("3.459"),
    answer("17"),
    correct = "Richtig!",
    incorrect = "Leider falsch: 29.579 Plastikstücke wurden hier gefunden.",
    allow_retry = TRUE,
    try_again_button = "Nochmal versuchen"
  )
)
```


### Und jetzt Ihr
Diese Woche möchten wir die Präsenzzeit nutzen, um die folgenden Übungen zu besprechen. Ergänzt unseren Input gerne mit zudem mit Euren **Ideen, Fragen, Anregungen oder Kommentaren**. Es ist nicht schlimm, falls diese Woche noch gar nichts (komplexes) klappt, da wir das Gelernte in den nächsten Wochen wiederholen und vertiefen werden.

1. Überlegt: Welche **Fragen** möchtet Ihr den Daten noch stellen? Wie könnte eine Visualisierung oder eine zusammenfassende Statistik dabei helfen? Skizziert Eure Fragen gerne schriftlich.

2. Versucht, das zugehörige [**R Markdown: 05_ErsteDatenanalysenInR **](https://correlcloud.org/index.php/s/56cTMCbMPbYLEya){target="_blank"} zum Laufen zu bringen und es nachzuvollziehen.

3. In der ersten Einheit haben wir uns bei der Visualisierung vor allem der **Community Perspektive** gewidmet. Nun blicken wir auf die **Audit Perspektive**: Wie viel Plastik wurde wo für "Break Free From Plastic" gesammelt? Erstellt in dem heruntergeladenen RMarkdown ein **Punktediagramm** (Scatterplot) mit dem Datensatz `audit_plastic` für diese *Audit Perspektive*. Die Graphik soll `grand_total`, die **Anzahl der gesammelten Plastikstücke** auf der y-Achse und die **Kontinente** auf der x-Achse zeigen.

4. In der zweiten Einheit haben wir uns auf statistische Kennzahlen des `audit_plastic`-Datensatzes konzentriert. Nutzt nun den `community` Datensatz und erstellt eine **Tabelle**, welche die **Länder- und Freiwilligenanzahl je Kontinent** darstellt.

### Zusätzliche Ressourcen
- Die kostenlosen Kurse des [Statistischen Bundesamts](https://www.destatis.de/DE/Service/Statistik-Campus/E-Learning/eLearning-statistik.html;jsessionid=63AE25DDABD8853990FBE83F354C8911.live722?nn=206328){target="_blank"}
- Stocker T. C. und Steinke I. (2017): Statistik – Grundlagen und Methodik [verfügbar z.B. hier](https://www.beck-shop.de/stocker-steinke-de-gruyter-studium-statistik/product/32926361){target="_blank"}
- [R for Data Science (engl.)](https://r4ds.had.co.nz/){target="_blank"}
- [Statistics Fundamentals in R](https://app.dataquest.io/course/statistics-fundamentals-r){target="_blank"} auf DataQuest (engl.)
- [Lernvideos](https://www.youtube.com/watch?v=RRIsBFW8ovc){target="_blank"} zur Inferenzstatistik (dt.)